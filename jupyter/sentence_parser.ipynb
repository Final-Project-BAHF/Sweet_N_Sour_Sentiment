{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweet n Sour Sentiment on the Street\n",
    "Georgia Tech Data Science Bootcamp - Cohort 6\n",
    "Final Project\n",
    "Team Members:\n",
    "* Joseph Ayala\n",
    "* Andrew Behrman\n",
    "* Michael Fox\n",
    "* Michael Hankinson\n",
    "\n",
    "### Sentence Parser\n",
    "\n",
    "This notebook will iterate through a raw text files of Earnings Call Transcripts and parse them into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Files found:\n",
      " ['../data/raw_transcripts/TWTR-2019-Q3.txt', '../data/raw_transcripts/GE-2019-Q3.txt', '../data/raw_transcripts/CMG-2019-Q3.txt', '../data/raw_transcripts/UAA-2019-Q3.txt', '../data/raw_transcripts/NVDA-2020-Q2.txt', '../data/raw_transcripts/WFC-2019-Q3.txt', '../data/raw_transcripts/SBUX-2019-Q3.txt', '../data/raw_transcripts/IVZ-2019-Q3.txt', '../data/raw_transcripts/GM-2019-Q3.txt', '../data/raw_transcripts/CRM-2020-Q2.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# read in all txt files from the raw_transcripts folder\n",
    "txt_files = glob.glob(\"../data/raw_transcripts/*.txt\")\n",
    "\n",
    "# show the list of files that will be parsed\n",
    "print(f'{len(txt_files)} Files found:\\n {txt_files}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw_transcripts/TWTR-2019-Q3.txt: Read string of length 43522\n",
      "../data/raw_transcripts/GE-2019-Q3.txt: Read string of length 61978\n",
      "../data/raw_transcripts/CMG-2019-Q3.txt: Read string of length 57812\n",
      "../data/raw_transcripts/UAA-2019-Q3.txt: Read string of length 68566\n",
      "../data/raw_transcripts/NVDA-2020-Q2.txt: Read string of length 48193\n",
      "../data/raw_transcripts/WFC-2019-Q3.txt: Read string of length 64715\n",
      "../data/raw_transcripts/SBUX-2019-Q3.txt: Read string of length 69258\n",
      "../data/raw_transcripts/IVZ-2019-Q3.txt: Read string of length 57606\n",
      "../data/raw_transcripts/GM-2019-Q3.txt: Read string of length 58556\n",
      "../data/raw_transcripts/CRM-2020-Q2.txt: Read string of length 54550\n",
      "Total String Length: 584756\n"
     ]
    }
   ],
   "source": [
    "# read contents of files into one big string\n",
    "\n",
    "strRawText = \"\"\n",
    "\n",
    "for f in txt_files:\n",
    "    with open(f, 'r') as txt_file:\n",
    "        newText = txt_file.read().replace('\\n', ' ')\n",
    "        print(f'{f}: Read string of length {len(newText)}')\n",
    "        strRawText = strRawText + newText\n",
    "\n",
    "print(f'Total String Length: {len(strRawText)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5160 sentences\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# parse large string into array of sentences\n",
    "arr_sentences = sent_tokenize(strRawText)\n",
    "print(f'Found {len(arr_sentences)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output list of sentences to new file\n",
    "with open('../data/sentences_all.txt', 'w') as outfile:\n",
    "    outfile.write(\"\\n\".join(arr_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3000 sample sentences.\n"
     ]
    }
   ],
   "source": [
    "# get random sample of 3000 sentences with repeatable results\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "sample_sentences = random.sample(arr_sentences, 3000)\n",
    "\n",
    "# check sample size\n",
    "print(f'Selected {len(sample_sentences)} sample sentences.')\n",
    "\n",
    "# output sample of sentences to new file\n",
    "with open('../data/sentences_3000.txt', 'w') as outfile:\n",
    "    outfile.write(\"\\n\".join(sample_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py36 (gtfinalproj)",
   "language": "python",
   "name": "gtfinalproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
